{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n",
      "['Stephen Lynch', 'Logged In', 'Jayden', 'M', '0', 'Bell', '182.85669', 'free', 'Dallas-Fort Worth-Arlington, TX', 'PUT', 'NextSong', '1.54099E+12', '829', \"Jim Henson's Dead\", '200', '1.54354E+12', '91']\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "print(full_data_rows_list[0])\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"https://github.com/inigo-irigaray/nosql-cassandra-sparkify/blob/master/imgs/image_event_datafile_new.jpg">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Create Keyspace sparkify\n",
    "try:\n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS sparkify WITH REPLICATION = \\\n",
    "                    {'class': 'SimpleStrategy', 'replication_factor':1}\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Set KEYSPACE to the sparkify\n",
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### QUERY 1:\n",
    "\n",
    "    SELECT artist, song_title, song_length \\\n",
    "    FROM song_history \\\n",
    "    WHERE session_id=338 and item_in_session=4\n",
    "\n",
    "<p align=justify>We need to filter our queries based on the sessionId and itemInSesion, so these two columns will be our primary key. The sessionId will be set as the partition key to distribute data across nodes depending on the session, and ordering the data based on the itemInSession (which will be the clustering column).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "try:\n",
    "    session.execute(\"CREATE TABLE IF NOT EXISTS song_history (session_id int,\\\n",
    "                                                              item_in_session int,\\\n",
    "                                                              song_title text,\\\n",
    "                                                              artist text,\\\n",
    "                                                              song_length float,\\\n",
    "                                                              PRIMARY KEY (session_id, item_in_session)\\\n",
    "                                                              )\"\n",
    "                   )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.DictReader(f)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_history (session_id, item_in_session, song_title, artist, song_length) \\\n",
    "                VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line['sessionId']), int(line['itemInSession']), line['song'],\n",
    "                                line['artist'], float(line['length'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(session_id=23, item_in_session=0, artist='Regina Spektor', song_length=191.08526611328125, song_title='The Calculation (Album Version)')\n",
      "Row(session_id=23, item_in_session=1, artist='Octopus Project', song_length=250.95791625976562, song_title='All Of The Champs That Ever Lived')\n",
      "Row(session_id=23, item_in_session=2, artist='Tegan And Sara', song_length=180.06158447265625, song_title='So Jealous')\n",
      "Row(session_id=23, item_in_session=3, artist='Dragonette', song_length=153.39056396484375, song_title='Okay Dolores')\n",
      "Row(session_id=23, item_in_session=4, artist='Lil Wayne / Eminem', song_length=229.58975219726562, song_title='Drop The World')\n"
     ]
    }
   ],
   "source": [
    "#Check if data was properly stored in the table\n",
    "try:\n",
    "    rows = session.execute(\"SELECT * FROM song_history LIMIT 5\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Faithless', song_title='Music Matters (Mark Knight Dub)', song_length=495.30731201171875)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(\"SELECT artist, song_title, song_length \\\n",
    "                            FROM song_history \\\n",
    "                            WHERE session_id=%s and item_in_session=%s\",\n",
    "                           (338, 4))\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### QUERY 2:\n",
    "\n",
    "    SELECT artist, song_title, first_name, last_name, item_in_session \\\n",
    "    FROM artist_history \\\n",
    "    WHERE user_id=10 and session_id=182\n",
    "\n",
    "<p align=justify>We need to filter our queries based on the userId and sessionId, as well as having the data sorted by itemInSession. So these three columns will be our primary key. The userId and sessionId will be set as the composite partition key to distribute data across nodes depending on both ids, and the itemInSession will be the clustering column to order the data accordingly.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "try:\n",
    "    session.execute(\"CREATE TABLE IF NOT EXISTS artist_history (user_id int,\\\n",
    "                                                                session_id int,\\\n",
    "                                                                item_in_session int, \\\n",
    "                                                                artist text,\\\n",
    "                                                                song_title text,\\\n",
    "                                                                first_name text,\\\n",
    "                                                                last_name text,\\\n",
    "                                                                PRIMARY KEY ((user_id, session_id), item_in_session)\\\n",
    "                                                                )\"\n",
    "                   )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.DictReader(f)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO artist_history \\\n",
    "                            (user_id, session_id, item_in_session, artist, song_title, first_name, last_name) \\\n",
    "                            VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line['userId']), int(line['sessionId']), int(line['itemInSession']), line['artist'],\n",
    "                                line['song'], line['firstName'], line['lastName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(user_id=58, session_id=768, item_in_session=0, artist='System of a Down', first_name='Emily', last_name='Benson', song_title='Sad Statue')\n",
      "Row(user_id=58, session_id=768, item_in_session=1, artist='Ghostland Observatory', first_name='Emily', last_name='Benson', song_title='Stranger Lover')\n",
      "Row(user_id=58, session_id=768, item_in_session=2, artist='Evergreen Terrace', first_name='Emily', last_name='Benson', song_title='Zero')\n",
      "Row(user_id=85, session_id=776, item_in_session=2, artist='Deftones', first_name='Kinsley', last_name='Young', song_title='Head Up (LP Version)')\n",
      "Row(user_id=85, session_id=776, item_in_session=3, artist='The Notorious B.I.G.', first_name='Kinsley', last_name='Young', song_title='Playa Hater (Amended Version)')\n"
     ]
    }
   ],
   "source": [
    "#Check if data was properly stored in the table\n",
    "try:\n",
    "    rows = session.execute(\"SELECT * FROM artist_history LIMIT 5\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Down To The Bone', song_title=\"Keep On Keepin' On\", first_name='Sylvie', last_name='Cruz', item_in_session=0)\n",
      "Row(artist='Three Drives', song_title='Greece 2000', first_name='Sylvie', last_name='Cruz', item_in_session=1)\n",
      "Row(artist='Sebastien Tellier', song_title='Kilometer', first_name='Sylvie', last_name='Cruz', item_in_session=2)\n",
      "Row(artist='Lonnie Gordon', song_title='Catch You Baby (Steve Pitron & Max Sanna Radio Edit)', first_name='Sylvie', last_name='Cruz', item_in_session=3)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(\"SELECT artist, song_title, first_name, last_name, item_in_session \\\n",
    "                            FROM artist_history \\\n",
    "                            WHERE user_id=%s and session_id=%s\",\n",
    "                           (10, 182))\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### QUERY 3:\n",
    "\n",
    "    SELECT first_name, last_name \\\n",
    "    FROM user_history \\\n",
    "    WHERE song_title='All Hands Against His Own'\n",
    "\n",
    "<p align=justify>We need to filter our queries based on the song_title. Many people can have the same name, so userId will be used as a clustering column to differentiate between different users with the same name without duplicates or skipping people.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "try:\n",
    "    session.execute(\"CREATE TABLE IF NOT EXISTS user_history (song_title text,\\\n",
    "                                                              user_id int,\\\n",
    "                                                              first_name text,\\\n",
    "                                                              last_name text,\\\n",
    "                                                              PRIMARY KEY (song_title, user_id)\\\n",
    "                                                              )\"\n",
    "                   )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.DictReader(f)\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_history (song_title, user_id, first_name, last_name) \\\n",
    "                VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line['song'], int(line['userId']), line['firstName'], line['lastName']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(song_title=\"Wonder What's Next\", user_id=49, first_name='Chloe', last_name='Cuevas')\n",
      "Row(song_title=\"In The Dragon's Den\", user_id=49, first_name='Chloe', last_name='Cuevas')\n",
      "Row(song_title='Too Tough (1994 Digital Remaster)', user_id=44, first_name='Aleena', last_name='Kirby')\n",
      "Row(song_title='Rio De Janeiro Blue (Album Version)', user_id=49, first_name='Chloe', last_name='Cuevas')\n",
      "Row(song_title='My Place', user_id=15, first_name='Lily', last_name='Koch')\n"
     ]
    }
   ],
   "source": [
    "#Check if data was properly stored in the table\n",
    "try:\n",
    "    rows = session.execute(\"SELECT * FROM user_history LIMIT 5\")\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(first_name='Jacqueline', last_name='Lynch')\n",
      "Row(first_name='Tegan', last_name='Levine')\n",
      "Row(first_name='Sara', last_name='Johnson')\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    rows = session.execute(\"SELECT first_name, last_name \\\n",
    "                            FROM user_history \\\n",
    "                            WHERE song_title=%s\" %\n",
    "                           (\"'All Hands Against His Own'\"))\n",
    "    for row in rows:\n",
    "        print(row)\n",
    "except Exception as e:\n",
    "    print(e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Drop the table before closing out the sessions\n",
    "tables = [\"song_history\", \"artist_history\", \"user_history\"]\n",
    "for table in tables:\n",
    "    try:\n",
    "        session.execute(\"DROP TABLE %s\" % table)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
